{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>In the previous chapter, we saw that cleaning effects of C from B helped us segregate B and C quite well</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a simple sanity check, lets try segregating B from C on the dirty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabri\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\sabri\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\sabri\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.signal as sig\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = pd.read_csv(\"../assets/data/data_B.csv\", header=None)\n",
    "C = pd.read_csv(\"../assets/data/data_C.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2639, 24), (2322, 24))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape, C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classif_ABC = tf.keras.Sequential()\n",
    "model_classif_ABC.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences=True), input_shape=(24, 1)))\n",
    "model_classif_ABC.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1, activation='relu')))\n",
    "model_classif_ABC.add(tf.keras.layers.Flatten())\n",
    "model_classif_ABC.add(tf.keras.layers.Dropout(0.2))\n",
    "model_classif_ABC.add(tf.keras.layers.Dense(12, activation='relu'))\n",
    "model_classif_ABC.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
    "model_classif_ABC.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_summary(X, iqrl=0.25, iqrr=0.75):\n",
    "    '''\n",
    "    Return for each timestamp (hr) return min, max, 0.25 quantile, 0.75 quantile, mean, var\n",
    "    '''\n",
    "    return pd.DataFrame(np.array([np.min(X, axis=0), np.quantile(X, axis=0, q=iqrl), np.median(X, axis=0), \n",
    "          np.quantile(X, axis=0, q=iqrr), np.max(X, axis=0), np.mean(X, axis=0), np.var(X, axis=0), np.std(X, axis=0)]).transpose(),\n",
    "                        columns=[\"Min\", \"0.25Q\", \"Med\", \"0.75Q\", \"Max\", \"Mean\", \"Var\", \"StD\"])\n",
    "\n",
    "def trend(X, span = None):\n",
    "    '''\n",
    "    Return EWMA trend for signal samples\n",
    "    '''\n",
    "    if not span:\n",
    "        span = X.shape[1]\n",
    "    return pd.DataFrame(X).apply(lambda x: x.ewm(span=span).mean(), axis=1)\n",
    "\n",
    "def train_test_val_split(X, y=None, test_size=0.2,  val_size=0.4):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    if y.__len__() > 0:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "        X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=val_size)\n",
    "        return X_train, X_test, X_val, y_train, y_test, y_val\n",
    "    else:\n",
    "        X_train, X_test = train_test_split(X, test_size=test_size)\n",
    "        X_test, X_val = train_test_split(X_test, test_size=val_size)\n",
    "        return X_train, X_test, X_val\n",
    "\n",
    "def reshapeInput(X):\n",
    "    X_ = []\n",
    "    for x in X:\n",
    "        X_.append(x.reshape(-1,1))\n",
    "    return np.array(X_)\n",
    "\n",
    "def shapeInput(X):\n",
    "    X_ = []\n",
    "    for x in X:\n",
    "        X_.append(x.reshape(1,-1)[0])\n",
    "    return np.array(X_)\n",
    "\n",
    "\n",
    "def meanShift(X, window=None):\n",
    "    '''\n",
    "    Apply MA on convolved signal and compute rs means\n",
    "    '''\n",
    "    # At this point X must be EWMA convolved already\n",
    "    if not window:\n",
    "        window = X.shape[1] // 2\n",
    "    return pd.DataFrame(X).apply(lambda x: x.rolling(window=window).mean(), axis=1).iloc[:,window-1:]\n",
    "\n",
    "def gradient(X, shift=1, threshold=0):\n",
    "    '''\n",
    "    First order gradient of signal. Eq to diff for discrete signal\n",
    "    '''\n",
    "    return pd.DataFrame(X).apply(lambda x: x.diff(periods=shift), axis=1).iloc[:,threshold:]\n",
    "\n",
    "def bucketPeaks(peakIndex):\n",
    "    '''\n",
    "    Bucket into first half and second half\n",
    "    '''\n",
    "    return(sum(peakIndex <= 12), sum(peakIndex > 12)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.row_stack((B,C))\n",
    "Y = [0]*(B.__len__()) + [1]*C.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = train_test_val_split(X, tf.keras.utils.to_categorical(Y), test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001F915188EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001F915188EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "40/45 [=========================>....] - ETA: 0s - loss: 0.6925 - accuracy: 0.5250WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FB0ADE95E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001FB0ADE95E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "45/45 [==============================] - 3s 23ms/step - loss: 0.6924 - accuracy: 0.5249 - val_loss: 0.6857 - val_accuracy: 0.5729\n",
      "Epoch 2/120\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.6898 - accuracy: 0.5377 - val_loss: 0.6823 - val_accuracy: 0.5729\n",
      "Epoch 3/120\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.6896 - accuracy: 0.5346 - val_loss: 0.6825 - val_accuracy: 0.5729\n",
      "Epoch 4/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6898 - accuracy: 0.5295 - val_loss: 0.6804 - val_accuracy: 0.5729\n",
      "Epoch 5/120\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.6866 - accuracy: 0.5292 - val_loss: 0.6747 - val_accuracy: 0.5628\n",
      "Epoch 6/120\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.6838 - accuracy: 0.5693 - val_loss: 0.6734 - val_accuracy: 0.5678\n",
      "Epoch 7/120\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.6831 - accuracy: 0.5637 - val_loss: 0.6629 - val_accuracy: 0.5930\n",
      "Epoch 8/120\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.6762 - accuracy: 0.5831 - val_loss: 0.6551 - val_accuracy: 0.6432\n",
      "Epoch 9/120\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.6740 - accuracy: 0.6088 - val_loss: 0.6474 - val_accuracy: 0.5678\n",
      "Epoch 10/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6634 - accuracy: 0.6030 - val_loss: 0.6484 - val_accuracy: 0.6432\n",
      "Epoch 11/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6597 - accuracy: 0.6117 - val_loss: 0.6391 - val_accuracy: 0.6533\n",
      "Epoch 12/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6594 - accuracy: 0.5989 - val_loss: 0.6431 - val_accuracy: 0.6030\n",
      "Epoch 13/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6512 - accuracy: 0.6279 - val_loss: 0.6515 - val_accuracy: 0.6181\n",
      "Epoch 14/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6767 - accuracy: 0.6153 - val_loss: 0.6461 - val_accuracy: 0.6080\n",
      "Epoch 15/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6597 - accuracy: 0.6097 - val_loss: 0.6455 - val_accuracy: 0.6583\n",
      "Epoch 16/120\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.6535 - accuracy: 0.6307 - val_loss: 0.6595 - val_accuracy: 0.6231\n",
      "Epoch 17/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6533 - accuracy: 0.6104 - val_loss: 0.6457 - val_accuracy: 0.5930\n",
      "Epoch 18/120\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.6443 - accuracy: 0.6239 - val_loss: 0.6240 - val_accuracy: 0.6533\n",
      "Epoch 19/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6463 - accuracy: 0.6183 - val_loss: 0.6297 - val_accuracy: 0.6231\n",
      "Epoch 20/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6413 - accuracy: 0.6254 - val_loss: 0.6367 - val_accuracy: 0.6131\n",
      "Epoch 21/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6367 - accuracy: 0.6237 - val_loss: 0.6243 - val_accuracy: 0.6382\n",
      "Epoch 22/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6375 - accuracy: 0.6204 - val_loss: 0.6237 - val_accuracy: 0.6281\n",
      "Epoch 23/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6293 - accuracy: 0.6301 - val_loss: 0.6333 - val_accuracy: 0.6332\n",
      "Epoch 24/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6418 - accuracy: 0.6148 - val_loss: 0.6230 - val_accuracy: 0.6181\n",
      "Epoch 25/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6474 - accuracy: 0.6066 - val_loss: 0.6253 - val_accuracy: 0.6231\n",
      "Epoch 26/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6419 - accuracy: 0.6096 - val_loss: 0.6297 - val_accuracy: 0.6131\n",
      "Epoch 27/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6354 - accuracy: 0.6223 - val_loss: 0.6256 - val_accuracy: 0.6432\n",
      "Epoch 28/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6289 - accuracy: 0.6287 - val_loss: 0.6219 - val_accuracy: 0.6231\n",
      "Epoch 29/120\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.6433 - accuracy: 0.5997 - val_loss: 0.6367 - val_accuracy: 0.6030\n",
      "Epoch 30/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6367 - accuracy: 0.6119 - val_loss: 0.6386 - val_accuracy: 0.6080\n",
      "Epoch 31/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6416 - accuracy: 0.6099 - val_loss: 0.6465 - val_accuracy: 0.6131\n",
      "Epoch 32/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6487 - accuracy: 0.6050 - val_loss: 0.6244 - val_accuracy: 0.6131\n",
      "Epoch 33/120\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.6338 - accuracy: 0.6059 - val_loss: 0.6132 - val_accuracy: 0.6281\n",
      "Epoch 34/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6410 - accuracy: 0.6184 - val_loss: 0.6155 - val_accuracy: 0.6382\n",
      "Epoch 35/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6352 - accuracy: 0.6155 - val_loss: 0.6303 - val_accuracy: 0.5930\n",
      "Epoch 36/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6429 - accuracy: 0.6172 - val_loss: 0.6334 - val_accuracy: 0.6432\n",
      "Epoch 37/120\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.6357 - accuracy: 0.6207 - val_loss: 0.6306 - val_accuracy: 0.6131\n",
      "Epoch 38/120\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.6467 - accuracy: 0.6059 - val_loss: 0.6146 - val_accuracy: 0.6382\n",
      "Epoch 39/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6374 - accuracy: 0.6163 - val_loss: 0.6214 - val_accuracy: 0.6382\n",
      "Epoch 40/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6405 - accuracy: 0.6121 - val_loss: 0.6157 - val_accuracy: 0.6382\n",
      "Epoch 41/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6304 - accuracy: 0.6211 - val_loss: 0.6168 - val_accuracy: 0.6080\n",
      "Epoch 42/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6287 - accuracy: 0.6116 - val_loss: 0.6088 - val_accuracy: 0.6332\n",
      "Epoch 43/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6327 - accuracy: 0.6160 - val_loss: 0.6253 - val_accuracy: 0.6382\n",
      "Epoch 44/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6281 - accuracy: 0.6183 - val_loss: 0.6260 - val_accuracy: 0.6281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6375 - accuracy: 0.6095 - val_loss: 0.6287 - val_accuracy: 0.6131\n",
      "Epoch 46/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6314 - accuracy: 0.6346 - val_loss: 0.6181 - val_accuracy: 0.6332\n",
      "Epoch 47/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6213 - accuracy: 0.6416 - val_loss: 0.6240 - val_accuracy: 0.5930\n",
      "Epoch 48/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6223 - accuracy: 0.6171 - val_loss: 0.6121 - val_accuracy: 0.6332\n",
      "Epoch 49/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6197 - accuracy: 0.6207 - val_loss: 0.6205 - val_accuracy: 0.6030\n",
      "Epoch 50/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6239 - accuracy: 0.6347 - val_loss: 0.6179 - val_accuracy: 0.6281\n",
      "Epoch 51/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6221 - accuracy: 0.6177 - val_loss: 0.6172 - val_accuracy: 0.6382\n",
      "Epoch 52/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6318 - accuracy: 0.6196 - val_loss: 0.6158 - val_accuracy: 0.6432\n",
      "Epoch 53/120\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.6270 - accuracy: 0.6107 - val_loss: 0.6297 - val_accuracy: 0.5980\n",
      "Epoch 54/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6212 - accuracy: 0.6228 - val_loss: 0.6262 - val_accuracy: 0.5829\n",
      "Epoch 55/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6421 - accuracy: 0.5976 - val_loss: 0.6174 - val_accuracy: 0.6281\n",
      "Epoch 56/120\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.6320 - accuracy: 0.6045 - val_loss: 0.6158 - val_accuracy: 0.6432\n",
      "Epoch 57/120\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.6313 - accuracy: 0.6086 - val_loss: 0.6232 - val_accuracy: 0.6030\n",
      "Epoch 58/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6203 - accuracy: 0.6284 - val_loss: 0.6096 - val_accuracy: 0.6432\n",
      "Epoch 59/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6217 - accuracy: 0.6134 - val_loss: 0.6353 - val_accuracy: 0.5779\n",
      "Epoch 60/120\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.6211 - accuracy: 0.6273 - val_loss: 0.6255 - val_accuracy: 0.6030\n",
      "Epoch 61/120\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.6188 - accuracy: 0.6070 - val_loss: 0.6233 - val_accuracy: 0.6080\n",
      "Epoch 62/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6218 - accuracy: 0.6199 - val_loss: 0.6135 - val_accuracy: 0.6332\n",
      "Epoch 63/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6145 - accuracy: 0.6216 - val_loss: 0.6071 - val_accuracy: 0.6432\n",
      "Epoch 64/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6330 - accuracy: 0.6168 - val_loss: 0.6250 - val_accuracy: 0.6231\n",
      "Epoch 65/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6228 - accuracy: 0.6176 - val_loss: 0.6115 - val_accuracy: 0.6482\n",
      "Epoch 66/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6146 - accuracy: 0.6242 - val_loss: 0.6192 - val_accuracy: 0.6432\n",
      "Epoch 67/120\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 0.6199 - accuracy: 0.6208 - val_loss: 0.6419 - val_accuracy: 0.5879\n",
      "Epoch 68/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6233 - accuracy: 0.6054 - val_loss: 0.6227 - val_accuracy: 0.6332\n",
      "Epoch 69/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6140 - accuracy: 0.6320 - val_loss: 0.6148 - val_accuracy: 0.6332\n",
      "Epoch 70/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6184 - accuracy: 0.6128 - val_loss: 0.6373 - val_accuracy: 0.6030\n",
      "Epoch 71/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6242 - accuracy: 0.6233 - val_loss: 0.6210 - val_accuracy: 0.6030\n",
      "Epoch 72/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6126 - accuracy: 0.6315 - val_loss: 0.6409 - val_accuracy: 0.6080\n",
      "Epoch 73/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6171 - accuracy: 0.6118 - val_loss: 0.6211 - val_accuracy: 0.6030\n",
      "Epoch 74/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6193 - accuracy: 0.6187 - val_loss: 0.6296 - val_accuracy: 0.6080\n",
      "Epoch 75/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6179 - accuracy: 0.6163 - val_loss: 0.6227 - val_accuracy: 0.5930\n",
      "Epoch 76/120\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.6180 - accuracy: 0.6094 - val_loss: 0.6318 - val_accuracy: 0.5980\n",
      "Epoch 77/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6204 - accuracy: 0.6121 - val_loss: 0.6097 - val_accuracy: 0.6432\n",
      "Epoch 78/120\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.6141 - accuracy: 0.6281 - val_loss: 0.6108 - val_accuracy: 0.6332\n",
      "Epoch 79/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6197 - accuracy: 0.6033 - val_loss: 0.6169 - val_accuracy: 0.6131\n",
      "Epoch 80/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6106 - accuracy: 0.6231 - val_loss: 0.6149 - val_accuracy: 0.6231\n",
      "Epoch 81/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6091 - accuracy: 0.6399 - val_loss: 0.6318 - val_accuracy: 0.5779\n",
      "Epoch 82/120\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.6164 - accuracy: 0.6158 - val_loss: 0.6484 - val_accuracy: 0.5980\n",
      "Epoch 83/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6303 - accuracy: 0.6122 - val_loss: 0.6179 - val_accuracy: 0.6131\n",
      "Epoch 84/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6147 - accuracy: 0.6372 - val_loss: 0.6299 - val_accuracy: 0.6080\n",
      "Epoch 85/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6112 - accuracy: 0.6290 - val_loss: 0.6113 - val_accuracy: 0.6482\n",
      "Epoch 86/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6211 - accuracy: 0.6076 - val_loss: 0.6214 - val_accuracy: 0.6231\n",
      "Epoch 87/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6192 - accuracy: 0.6174 - val_loss: 0.6430 - val_accuracy: 0.5829\n",
      "Epoch 88/120\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.6214 - accuracy: 0.6157 - val_loss: 0.6200 - val_accuracy: 0.5930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f9151deb08>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classif_ABC.fit(reshapeInput(X_train), y_train, \n",
    "          epochs=120, batch_size=100,\n",
    "          validation_data=(reshapeInput(X_val), y_val),\n",
    "         callbacks=tf.keras.callbacks.EarlyStopping(patience=25, restore_best_weights=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabri\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[111,  47],\n",
       "       [ 60,  80]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(np.argmax(y_test, axis=1), model_classif_ABC.predict_classes(reshapeInput(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While many B's were classified as B's, a lot of C's were misclassified as B's. This effect is due to signal pollution from tool C patterns, that we cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Also a sanity check would be to see if a simple ML model can perform just as well as the LSTM model we used in the previous chapter, ON THE CLEANED B vs C data<br/>\n",
    "Lets use a ML model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = pd.read_csv(\"../assets/data/cleaned/B.csv\", index_col=0)\n",
    "C = pd.read_csv(\"../assets/data/cleaned/C.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.row_stack((B,C))\n",
    "Y = [0]*(B.__len__()) + [1]*C.__len__()\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = train_test_val_split(X, tf.keras.utils.to_categorical(Y), test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44, 21],\n",
       "       [16, 66]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier().fit(X_train, np.argmax(y_train, axis=1))\n",
    "confusion_matrix(np.argmax(y_test, axis=1), rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noice !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
